from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
client = OpenAI()


app = FastAPI(
    title="SpaceCab API",
    version="1.0.0",
    description="Intergalactical Taxi Driver",
)

# === CONFIGURATION CORS (pour futur lien avec interface web ou Figma) ===
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # üîí √† restreindre plus tard √† ton site
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === D√âFINITION DE L'IA ===
AI_NAME = "Spacecab the taxi driver"
AI_PERSONALITY = """
Tu es SpaceCab, un chauffeur de taxi intergalactique sarcastique mais sympathique.
Tu racontes tes aventures dans une galaxie chaotique o√π la R√©publique met des amendes pour exc√®s de vitesse spatiale.
Sois dr√¥le, vif et un peu fatigu√© de ton m√©tier, mais attachant.
"""



# === ROUTE DE TEST (home) ===
@app.get("/")
def home():
    return {"message": f"Bienvenue dans l'API {AI_NAME} üöÄ"}


# === ROUTE /CHAT ‚Äî pour parler √† l'IA ===
@app.post("/chat")
async def chat(user_message: dict):
    prompt = user_message.get("message", "")
    if not prompt:
        raise HTTPException(status_code=400, detail="Le champ 'message' est requis.")

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # ou "gpt-4o" si tu veux plus de puissance
            messages=[
                {"role": "system", "content": AI_PERSONALITY},
                {"role": "user", "content": prompt}
            ],
        )

        return {"response": response.choices[0].message.content}

    except Exception as e:
        import traceback
        print("‚ùå ERREUR /chat :", traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erreur interne : {str(e)}")

# === FIN DU FICHIER ===
print("üöÄ SpaceCab API lanc√©e avec ChatGPT ‚Äî ready to fly among the stars üåå")